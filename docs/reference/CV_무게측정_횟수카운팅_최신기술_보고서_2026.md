# CV 기반 무게 측정 & 횟수 카운팅 — 최신 기술 종합 보고서 (2024-2026)

> 작성일: 2026-02-11 | 대상: V2log 앱 — 플레이트 로드 + 프리웨이트 운동

---

## 1. 횟수 카운팅 (Rep Counting) — "이건 지금 바로 할 수 있다"

### 핵심 기술: 포즈 추정 (Pose Estimation)

| 모델 | 키포인트 | 모바일 FPS | Flutter 지원 |
|------|---------|-----------|-------------|
| **MediaPipe BlazePose** | 33개 (3D) | 10-40 FPS | `google_mlkit_pose_detection` |
| **MoveNet Lightning** | 17개 | 25-40+ FPS | `tflite_flutter` |
| **YOLO11 Pose** | 17개 | 25-40 FPS | TFLite 변환 가능 |
| **RTMPose-s** | 17개 | 70+ FPS (SD865) | 커스텀 필요 |
| **DETRPose** (2025 신규) | 17개 | GPU 전용 | 모바일 미지원 |
| **Meta Sapiens** (2024) | 308개 | 모바일 불가 | 0.3B 파라미터 최소 |

### 횟수 카운팅 알고리즘 정확도 (최신 SOTA)

| 방법 | 연도 | 정확도(MAE↓) | OBO(↑) | 특징 |
|------|------|-------------|---------|------|
| **PoseRAC** | 2024 | **0.211** | **0.599** | 포즈 기반, 가벼움 |
| **ESCounts** | ACCV 2024 | **0.21** | **0.56** | 제로샷 가능 |
| **CountLLM** | CVPR 2025 | — | — | LLM 기반 (최초!) |
| **BiLSTM** | 2024 | 랩 99%, 짐 88% | — | 실용적 |
| Peak/Valley (각도) | 전통적 | 90-95% | — | 가장 단순 |

> **해석**: MAE 0.21 = 평균적으로 0.21개 차이. 10개 하면 거의 정확히 10개로 카운팅.
> OBO 0.599 = 약 60%가 ±1개 이내.

### 실제 환경 vs 실험실 차이

BiLSTM 논문(2024) 데이터:
- **실험실**: 99.24% 정확도
- **집**: 95.05% (-4.19%)
- **헬스장**: 87.91% (-11.33%)

> 헬스장에서는 조명, 카메라 각도, 다른 사람/기구 방해로 정확도 약 11% 하락.
> 하지만 88%면 10개 중 9개는 정확히 맞춤.

---

## 2. 무게 감지 (Weight Detection) — "아직 완전 자동은 없다, 하지만..."

### 현재 상황: 왜 어려운가

| 접근 방식 | 기술 | 정확도 | 문제점 |
|-----------|------|--------|--------|
| **색상 인식** (IWF 규격) | HSV 색상 분할 | 가능하지만 제한적 | 비표준 플레이트(검은색), 조명 변화, 색 바램 |
| **OCR** (플레이트 글씨 읽기) | PaddleOCR, YOLO | 정면만 가능 | 바벨에 끼우면 글씨가 옆으로 → 못 읽음 |
| **깊이 감지** (두께로 개수 세기) | LiDAR, 단안 깊이 | ±1cm 정도 | 플레이트가 붙어있으면 구분 불가 |
| **객체 감지** (YOLO로 플레이트 탐지) | YOLOv8~YOLO26 | 바벨 감지 90-95% | 개별 플레이트 중량 식별은 미해결 |
| **Grounding DINO** (텍스트→탐지) | Transformer | 작동하지만 느림 | 모바일 불가, 프롬프트에 민감 |

### 결정적 GAP

**"바벨에 몇 kg 플레이트가 몇 장 끼워져 있는지"를 카메라로 자동 계산하는 시스템은 2026년 현재 아직 없다.**

바벨 자체를 감지하는 건 90-95% 되지만, 개별 플레이트의 "종류(무게)"를 구분하는 건 아직 연구 단계.

### 희망적인 최신 발전들

#### 2-1. YOLO 모델의 비약적 발전 (2024-2026)

| 모델 | 출시 | 추론 속도 | 핵심 혁신 | mAP (COCO) |
|------|------|----------|----------|------------|
| YOLOv9 | 2024.02 | 11.5ms | PGI + GELAN 아키텍처 | ~53.0 |
| YOLOv10 | 2024.05 | **1.84ms** | NMS-free (후처리 불필요) | ~38.5 |
| YOLO11 | 2024.10 | 2.4ms | v8 대비 22% 작아짐 | ~39.5 |
| YOLOv12 | 2025 | 4.6ms | Attention 메커니즘 도입 | ~40.6 |
| **YOLO26** | 2025.09 | 경쟁적 | 소형 객체 탐지 특화(STAL) | ~41+ |
| **RF-DETR** | 2025.03 | 5ms 이하 | COCO 60+% mAP (최초!) | 60.6 |

> 2ms = 1초에 500장 분석 가능. 핸드폰에서도 실시간 플레이트 감지 가능한 속도.
> YOLO26의 STAL = "작은 물체 탐지" 특화 → 멀리서 찍은 플레이트도 감지 가능.

#### 2-2. 학습 데이터셋 존재 (Roboflow)

| 데이터셋 | 이미지 수 | 내용 |
|----------|----------|------|
| Weight Plates | 957장 | 무게 플레이트 |
| Gym Equipment (Bangkit) | 6,620장 | 헬스장 기구 전체 |
| All Gym Equipment (FitFuel) | 1,947장 | 종합 기구 |
| Barbell Detection (Gym Pal) | 208장 | 바벨 탐지 |
| Bench Press Detection | 424장 | 벤치프레스 특화 |

> **GAP**: 이 데이터셋들은 개별 플레이트 중량 라벨(예: "25kg 빨간 플레이트")이 없음.
> 커스텀 데이터셋 구축(5,000장+)이 필요.

#### 2-3. 바벨 속도 추적은 이미 검증됨 (2024)

학술 검증 연구: 스마트폰 CV 앱 vs 골드 스탠다드 Vicon 모션 캡처 (20명 파워리프터)
- **상관관계 r=0.93**
- **오차 0.01-0.04 m/s**
- **결론: 하드웨어 센서와 동등한 수준**

> 바벨 속도 측정은 핸드폰 카메라로도 수십만원짜리 전문 장비와 같은 정확도.

---

## 3. 다른 산업에서의 CV 활용 (적용 가능한 기술)

| 산업 | CV 활용 방식 | V2log 적용 가능 포인트 |
|------|-------------|---------------------|
| **제조업** (컨베이어 벨트) | 라인 통과 물체 개수 세기 (YOLO) | 바벨 위 플레이트 개수 세기와 동일 원리 |
| **소매/유통** (매장 진열) | 선반 위 상품 인식 (**99.5% 정확도**) | 플레이트 종류 인식과 동일 파이프라인 |
| **스포츠 분석** | 공 추적, 선수 포즈 (FIFA SAOT) | 바벨 궤적 + 선수 포즈 분석에 직접 적용 |
| **물리치료** | 관절 각도 측정, 동작 분석 | 운동 폼 체크에 바로 적용 |
| **건설업** | PPE 착용 감지 (물체+포즈 결합) | "사람+바벨+플레이트" 다중 감지에 동일 구조 |

> 마트 진열대 상품 인식(99.5%)과 플레이트 종류 인식은 같은 기술 파이프라인.

---

## 4. 피트니스 업계 주요 제품/경쟁사 현황 (2024-2026)

| 회사 | 방식 | 무게 감지? | 최신 동향 |
|------|------|----------|----------|
| **Peloton IQ** (2025 출시!) | 내장 카메라 + AI | 자동 횟수 + 폼 분석 | 올해 최대 CV 피트니스 출시 |
| **Tonal 2** (CES 2025) | 17개 센서 + 카메라 | 디지털 무게 (자동) | 500 데이터포인트/초, $3,795+ |
| **Tempo** | 3D ToF 카메라 | 사용자 입력 기반 | 앱 전용 모델로 전환 |
| **Kemtai** | 순수 소프트웨어 | 없음 | 111개 모션 포인트, 2000+ 운동 |
| **Onyx** | 핸드폰 카메라 | 없음 | Cure.fit에 인수됨 |
| **VAY Sports** | 핸드폰 카메라 SDK | 없음 | B2B SDK 무료 제공 |
| **Speediance** | AI 스마트 홈짐 | 디지털 무게 | 220lb 적응형, 실시간 폼 교정 |
| **Exersight** (신규) | AI 짐 카메라 | "자동 무게 추적" 주장 | 대기자 명단만 (상세 미공개) |

> **핵심**: Peloton까지 2025년에 CV를 전면 도입. 하지만 **프리웨이트 무게 자동 감지를 하는 곳은 아직 없음** → **블루오션**.

### 비즈니스 모델 비교

| 회사 | 모델 | CV 기능 위치 | 월 구독료 |
|------|------|------------|----------|
| **Tonal** | 하드웨어 + 필수 구독 | 구독에 포함 | $59.95/mo |
| **Peloton** | 하드웨어 + 단계별 구독 | All-Access 전용 | $49.99/mo |
| **Tempo** | 하드웨어 + 구독 | 구독에 포함 | ~$39/mo |
| **Kemtai** | SaaS (B2B + B2C) | CV가 핵심 제품 | 기업 가격 |
| **Onyx** | 프리미엄 앱 | 프리미엄 전용 | ~$14.99/mo |
| **VAY Sports** | 무료 앱 (B2B SDK) | 무료 | B2B 라이선스 |

---

## 5. 모바일 하드웨어 발전 (왜 지금이 적기인가)

| 칩 | NPU 성능 | 출시 | 의미 |
|----|----------|------|------|
| Apple A18 Pro | **35 TOPS** | 2024 | 2년 전 대비 2배 빠른 ML |
| Snapdragon 8 Elite | **45% 향상** | 2024 | 실시간 포즈 추정 30-60 FPS |
| Google Tensor G5 | 대폭 개선 예상 | 2025 | Pixel에서도 고급 ML 가능 |

> 2024년 이후 스마트폰 AI 칩이 급격히 발전 → 서버 없이 핸드폰에서 실시간 CV 가능.

### 모바일 포즈 추정 FPS 벤치마크

| 모델 | 안드로이드 (미드레인지) | 안드로이드 (플래그십) | iOS (iPhone 14+) |
|------|----------------------|---------------------|------------------|
| MoveNet Lightning | 25+ FPS | 40+ FPS | 30+ FPS |
| MediaPipe BlazePose | 10-30 FPS | 25-40 FPS | ~30 FPS |
| ML Kit Pose (Fast) | 15-30 FPS | 25-30 FPS | 25-30 FPS |
| ML Kit Pose (Accurate) | 2-15 FPS | 10-20 FPS | 15-25 FPS |
| YOLO11 Pose Nano | 10-20 FPS | 25-40 FPS | 20-30 FPS |

### 배터리 소비

- **MoveNet Lightning**: 가장 적은 배터리 소모
- 연속 카메라 + 포즈 추정: 시간당 약 **15-25% 배터리** 소모
- **최적화 전략**:
  - 매 2-3번째 프레임만 처리 (15 FPS면 횟수 카운팅에 충분)
  - 카메라 해상도 640x480으로 축소
  - 쉬는 시간에 포즈 추정 중지
  - GPU 위임(delegate) 사용 (CPU보다 전력 효율적)

---

## 6. 오픈소스 & 학술 자료

### CVPR 2025 주요 논문 (최신!)

| 논문 | 핵심 | 링크 |
|------|------|------|
| **M3GYM** | 82개 헬스장 세션, 8개 카메라, 47M 프레임 데이터셋 | [CVPR 2025](https://finalyou.github.io/M3GYM/) |
| **CountLLM** | 최초 LLM 기반 횟수 카운팅 | [arXiv 2503.17690](https://arxiv.org/abs/2503.17690) |
| **Period-LLM** | 멀티모달 LLM 주기적 동작 분석 | [arXiv 2505.24476](https://arxiv.org/abs/2505.24476) |

### 주요 학술 논문 (2024-2026)

| 논문 | 연도 | 핵심 | 링크 |
|------|------|------|------|
| **LiFT** | 2025 | 비전-언어 모델, 1900+ 운동, 85.3% OBO | [arXiv 2506.06480](https://arxiv.org/abs/2506.06480) |
| **BiLSTM Fitness Classifier** | 2024 | 4종 운동 99% 분류, 88% 헬스장 | [arXiv 2411.11548](https://arxiv.org/abs/2411.11548) |
| **PoseRAC** | 2024 | 포즈 기반 횟수 카운팅 SOTA | [arXiv 2308.08632](https://arxiv.org/abs/2308.08632) |
| **ESCounts** | ACCV 2024 | 제로샷 횟수 카운팅 | [arXiv 2403.18074](https://arxiv.org/abs/2403.18074) |
| **HTRM-Net** | 2024 | 하이브리드 시간 관계 모델링 | [arXiv 2412.07233](https://arxiv.org/abs/2412.07233) |
| **IVAC-P2L** | TMM 2025 | 비정규 반복 패턴 모델링 | [arXiv 2403.11959](https://arxiv.org/abs/2403.11959) |
| **Barbell Squat Coaching** | 2025 | CV 스쿼트 코칭, F1 87-100% | [arXiv 2503.23731](https://arxiv.org/abs/2503.23731) |
| **RTMO** | CVPR 2024 | 실시간 다중 인물 포즈 | [CVPR 2024](https://arxiv.org/abs/2312.07526) |
| **DETRPose** | 2025 | 트랜스포머 기반 실시간 포즈 | [arXiv 2506.13027](https://arxiv.org/abs/2506.13027) |
| **OVR Dataset** | 2024 | Google DeepMind, 72K+ 비디오 | [arXiv 2407.17085](https://arxiv.org/abs/2407.17085) |

### Flutter에서 바로 쓸 수 있는 오픈소스

| 프로젝트 | 설명 | 링크 |
|----------|------|------|
| `google_mlkit_pose_detection` | 공식 Flutter 플러그인, 33개 3D 랜드마크 | [pub.dev](https://pub.dev/packages/google_mlkit_pose_detection) |
| **mediapipe-flutter** (ThinkSys) | MediaPipe Pose Flutter iOS/Android | [GitHub](https://github.com/Thinksys/mediapipe-flutter) |
| **Coach.ai** | Flutter MoveNet 피트니스 앱 | [GitHub](https://github.com/MohEsmail143/coach-ai) |
| **Fitness_Counter** | Flutter PoseNet 횟수 카운터 | [GitHub](https://github.com/AshwinB-hat/Fitness_Counter) |
| **flutter_body_detection** | MLKit 포즈 + 셀피 세그멘테이션 | [GitHub](https://github.com/0x48lab/flutter_body_detection) |

### 바벨/무게 관련 오픈소스

| 프로젝트 | 설명 | 링크 |
|----------|------|------|
| **BarbellCV** | 바벨 추적 + 속도 분석 | [GitHub](https://github.com/tlancon/barbellcv) |
| **AI_Gym_trainer** | 덤벨 봉, 무게 플레이트 감지 | [GitHub](https://github.com/Aakash181/AI_Gym_trainer) |
| **Deadlift Visual Analyzer** | 데드리프트 자세 분석 | [GitHub](https://github.com/mattiolato98/deadlift-visual-analyzer) |
| **AIGYM (YOLOv8)** | 운동 AI | [GitHub](https://github.com/Devision789/Computervision_AIGYM) |
| **Exercise Recognition AI** | LSTM 97.78% + Attention 100% | [GitHub](https://github.com/chrisprasanna/Exercise_Recognition_AI) |
| **OpenCV Bar Tracker** | 바벨 경로 추적 | [GitHub](https://github.com/wllgrnt/opencv-bar-tracker) |
| **ATG.AI** | 자동 스쿼트 깊이 판정 | [GitHub](https://github.com/RanGlad12/ATG.AI) |

### 데이터셋

| 데이터셋 | 규모 | 내용 | 출처 |
|----------|------|------|------|
| **M3GYM** | 47M 프레임 | 82 세션, 8 카메라, 50+ 피험자 | CVPR 2025 |
| **OVR** | 72K+ 비디오 | Kinetics + Ego4D | Google DeepMind |
| **RepCount** | ~1.5K 비디오 | 스포츠/운동 | SVIP Lab |
| **Olympia (LiFT)** | 7,618 비디오, 152K QA | 1,900+ 운동 | LiFT 논문 |
| **Fit3D** | 3M+ 이미지 | 37+ 운동, 4 카메라 | fit3d.imar.ro |
| **Countix** | 8.7K 비디오 | 일반 반복 동작 | Google Research |
| **Gym Equipment (Bangkit)** | 6,620 이미지 | 헬스장 기구 | Roboflow |
| **Weight Plates** | 957 이미지 | 무게 플레이트 | Roboflow |

### 파운데이션 모델 (향후 활용 가능)

| 모델 | 역할 | 피트니스 적용 |
|------|------|-------------|
| **DINOv2** (Meta) | 자기지도 비주얼 피처 | 라벨 없이 운동 분류 |
| **SAM 2** (Meta) | 비디오 객체 분할 | 바벨/플레이트 프레임 간 추적 |
| **FoundationPose** (NVIDIA, CVPR 2024) | 새 물체 6D 포즈 추정 | 학습 없이 바벨 3D 위치/방향 추적 |
| **YOLO26** (Ultralytics) | 실시간 객체 감지 | 무게 플레이트, 바벨, 기구 감지 |

---

## 7. 기술 접근법 비교

### 횟수 카운팅: 규칙 기반 vs ML 기반

| 항목 | 규칙 기반 (관절 각도 임계값) | ML 기반 (학습된 카운팅) |
|------|---------------------------|----------------------|
| **접근법** | 운동별 각도 임계값 정의 | 비디오/포즈 시퀀스로 신경망 학습 |
| **지연시간** | 즉시, 낮은 연산량 | 모델 크기에 따라 다름 |
| **정확도** | 잘 정의된 운동에서 90-95% | OBO 기준 91%+ |
| **확장성** | 나쁨 (운동별 수동 규칙 작성) | 좋음 (데이터로 학습, 새 운동 일반화) |
| **투명성** | 완전히 설명 가능 | 블랙박스 |
| **초기 비용** | 낮음 (학습 데이터 불필요) | 높음 (라벨링된 데이터셋 필요) |
| **추천 용도** | MVP/프로토타입, 적은 운동 (<20개) | 프로덕션 앱, 대규모 운동 라이브러리 |

### 카메라 구성: 단일 vs 멀티

| 항목 | 단일 RGB 카메라 (핸드폰) | 멀티 카메라/RGB-D |
|------|-------------------------|------------------|
| **3D 정확도** | 관절 각도 오차 <20도 | 높음, 가림 문제 감소 |
| **설치** | 핸드폰 하나면 끝 | 보정된 멀티 카메라 설치 필요 |
| **사용자 경험** | 마찰 없음 | 복잡한 설치 |
| **비용** | 무료 (스마트폰) | 비쌈 ($200-400/카메라) |
| **추천** | **소비자 앱** (V2log) | 연구/임상 환경 |

### 온디바이스 vs 클라우드

| 항목 | 온디바이스 (모바일) | 클라우드 |
|------|-------------------|---------|
| **지연시간** | 2-30ms/프레임 | 100-500ms+ |
| **프라이버시** | 영상이 기기에만 존재 | 서버로 영상 전송 |
| **오프라인** | 인터넷 없이 작동 | 연결 필수 |
| **모델 크기** | 제한적 (3-50MB) | 무제한 |
| **비용** | 개발 후 무료 | 추론당 비용 발생 |
| **추천** | **피트니스 앱** (V2log) | 연구/분석용 |

---

## 8. 비즈니스 인사이트

### CV/AI 피트니스의 비즈니스 효과

| 지표 | 수치 |
|------|------|
| AI 개인화 → 사용자 유지율 | **50% 향상** |
| 게이미피케이션 + AI → 30일 리텐션 | **25-30% 증가** |
| 예측 분석 → 이탈 감소 | **30% 감소** |
| AI 피트니스 시장 (2025) | **$18.6B** |
| AI 피트니스 시장 (2035 예상) | **$59.8B** (연 12.3% 성장) |
| 피트니스 앱 시장 (2025) | **$6.86B** |
| 피트니스 앱 시장 (2030 예상) | **$25.8B** |

### 업계 리텐션 벤치마크

- 평균 30일 리텐션: **27.2%** (상위: 47.5%)
- 69%의 사용자가 90일 내 앱 이탈
- AI/CV 적용 시 리텐션 **12-50% 개선** 효과

---

## 9. V2log 최종 결론 및 권장 전략

### Phase 1: PoC (지금 바로 가능)

| 기능 | 방법 | 예상 정확도 | 난이도 |
|------|------|-----------|--------|
| **횟수 카운팅** | MediaPipe + 관절 각도 Peak/Valley | 88-95% | 쉬움 |
| **운동 종류 인식** | BiLSTM (30프레임 시퀀스) | 88-99% | 중간 |
| **바벨 궤적 추적** | YOLO + 중심점 추적 | 90-95% | 중간 |
| **무게 입력** | 수동 (카메라 제안 없이) | 100% | 없음 |

### Phase 1.5: 스마트 무게 입력 (3-6개월)

| 기능 | 방법 | 예상 정확도 | 난이도 |
|------|------|-----------|--------|
| **IWF 컬러 플레이트 인식** | HSV 색상 분할 + YOLO | 70-85% | 중간 |
| **플레이트 사진 OCR** | 세트 전 정면 촬영 → OCR | 80-90% | 중간 |
| **"AI 제안 → 원탭 확인" UX** | 위 결과 조합 | — | 핵심 UX |

### Phase 2: 고급 기능 (6-12개월)

| 기능 | 방법 | 필요한 것 |
|------|------|----------|
| **자동 무게 감지** | YOLO26 커스텀 학습 | 5,000장+ 플레이트 데이터셋 직접 구축 |
| **폼 분석** | 관절 각도 vs 이상적 궤적 비교 | 전문가 검증 |
| **속도 기반 훈련 (VBT)** | 바벨 속도 측정 (이미 검증됨) | 바벨 추적 모델 통합 |

### Phase 3: 미래 (12개월+)

| 기능 | 방법 |
|------|------|
| **LiFT 스타일 모델** | 비전-언어 트랜스포머, 1900+ 운동 |
| **SAM 2 활용** | 프레임 간 바벨 정밀 추적 |
| **CountLLM 스타일** | LLM 기반 범용 횟수 카운팅 |

---

## 핵심 요약

**횟수 카운팅** = 지금 바로 만들 수 있다. 기술도 있고, Flutter 패키지도 있고, 정확도도 88% 이상.

**무게 자동 감지** = 완전 자동은 아직 세계 어디에도 없다. 하지만:
1. 바벨 자체를 찾는 건 90-95%로 잘 됨
2. IWF 규격 컬러 플레이트면 색상으로 구분 가능 (조명 좋을 때)
3. YOLO 모델이 급속 발전 중 (1.84ms 추론 = 1초에 500장 분석)
4. **"AI가 추측 → 사용자가 원탭 확인" UX가 핵심** — 80% 맞추기만 해도 수동 입력보다 훨씬 빠름
5. Peloton, Tonal 등 대기업도 아직 프리웨이트 무게 자동 감지를 못 했으니 **선점 기회**

> **한 줄 결론**: Phase 1 PoC는 **횟수 카운팅 + 운동 인식**에 집중하고, 무게 감지는 **"사진 찍어서 AI 제안 → 원탭 확인"** 방식으로 시작하면 된다. 이것만으로도 시장에서 차별화 포인트가 된다.

---

## 참고 출처

### 논문
- [Ultralytics YOLO Evolution (YOLO26, YOLO11)](https://arxiv.org/html/2510.09653v2)
- [RF-DETR (ICLR 2026)](https://github.com/roboflow/rf-detr)
- [Grounding DINO (ECCV 2024)](https://github.com/IDEA-Research/GroundingDINO)
- [BiLSTM Fitness Classifier (arXiv 2411.11548)](https://arxiv.org/abs/2411.11548)
- [PoseRAC (arXiv 2308.08632)](https://arxiv.org/abs/2308.08632)
- [ESCounts (ACCV 2024)](https://arxiv.org/abs/2403.18074)
- [TransRAC (CVPR 2022)](https://arxiv.org/abs/2204.01018)
- [HTRM-Net (arXiv 2412.07233)](https://arxiv.org/abs/2412.07233)
- [CountLLM (CVPR 2025)](https://arxiv.org/abs/2503.17690)
- [M3GYM (CVPR 2025)](https://finalyou.github.io/M3GYM/)
- [LiFT (arXiv 2506.06480)](https://arxiv.org/abs/2506.06480)
- [DETRPose (arXiv 2506.13027)](https://arxiv.org/abs/2506.13027)
- [RTMO (CVPR 2024)](https://arxiv.org/abs/2312.07526)
- [Meta Sapiens (arXiv 2408.12569)](https://arxiv.org/abs/2408.12569)
- [Smartphone VBT Validation (PLOS ONE 2024)](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0313919)
- [Barbell Squat Coaching (arXiv 2503.23731)](https://arxiv.org/abs/2503.23731)

### 제품/회사
- [Peloton IQ](https://investor.onepeloton.com/news-releases/news-release-details/peloton-enters-new-era-ai-powered-peloton-iq-and-new-product)
- [Tonal 2 (CES 2025)](https://connectthewatts.com/2025/01/08/tonal-2-smart-home-gym-redefining-strength-training-at-ces-2025/)
- [Tempo](https://tempo.fit/)
- [Kemtai](https://kemtai.com/)
- [VAY Sports](https://vay-sports.com/)
- [Exersight](https://exersight.com/)
- [SpaceO AI Barbell Tracking](https://www.spaceo.ai/case-study/velocity-based-training/)
- [Metric VBT](https://www.metric.coach/)

### 오픈소스
- [MediaPipe](https://github.com/google-ai-edge/mediapipe)
- [Ultralytics YOLO](https://github.com/ultralytics/ultralytics)
- [MMPose (RTMPose)](https://github.com/open-mmlab/mmpose)
- [BarbellCV](https://github.com/tlancon/barbellcv)
- [google_mlkit_pose_detection](https://pub.dev/packages/google_mlkit_pose_detection)

### 시장 데이터
- [Grand View Research - Fitness Apps Market](https://www.grandviewresearch.com/industry-analysis/fitness-app-market)
- [Orangesoft - AI in Fitness 2026](https://orangesoft.co/blog/ai-in-fitness-industry)
- [Business of Apps - Health & Fitness Benchmarks](https://www.businessofapps.com/data/health-fitness-app-benchmarks/)
