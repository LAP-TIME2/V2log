# 02-12-10:46 진행상황 — CV 무게/횟수 자동 감지 논의

> 작성일: 2026-02-12 | V2log 앱에 CV 기반 자동 무게 측정 + 횟수 카운팅 도입 논의

---

## Q1. CV로 자동 무게/횟수 카운터를 넣으려면 어떻게 진행해야 하는가?

### 큰 그림: 3단계 접근

조사 결과 핵심 한 줄:
> **횟수 카운팅은 지금 바로 만들 수 있고, 무게 자동 감지는 세계 어디에도 완전한 게 없으니 단계적으로 접근한다.**

```
Phase 1 (지금 바로)     →  횟수 자동 카운팅 + 운동 종류 인식
Phase 1.5 (3~6개월 후)  →  "사진 찍으면 AI가 무게 추측 → 원탭 확인" UX
Phase 2 (6~12개월 후)   →  실시간 자동 무게 감지 + 폼 교정
```

### Phase 1: 횟수 자동 카운팅 (지금 바로 가능)

**사용 기술**: MediaPipe BlazePose (구글 AI 모델, 33개 관절 감지)
- Flutter 패키지: `google_mlkit_pose_detection` (바로 설치 가능)
- 속도: 핸드폰에서 10~40 FPS
- 정확도: 97.68%

**횟수 세는 방법**: 관절 각도 Peak/Valley 방식
- 예: 바이셉 컬 → 팔꿈치 각도 170° ↔ 40° 반복 감지 = 1회
- 운동별 관절+각도 규칙만 정의하면 됨
- 정확도: 88~95% (10개 중 9~10개 정확)

**V2log 적용 방식**: 운동 진행 화면(WorkoutScreen)에 카메라 모드 추가
- 현재: 세트마다 무게+횟수 수동 입력
- Phase 1 후: 횟수는 AI 자동 → **무게만 입력** (입력 시간 절반)

### Phase 1.5: 스마트 무게 입력 (3~6개월 후)

**무게 자동 감지가 어려운 이유**:
- "바벨에 몇 kg 플레이트가 몇 장인지" 자동 계산하는 시스템은 2026년 현재 **세계 어디에도 없음**
- 바벨에 끼우면 옆면만 보여서 글씨 못 읽음, 겹치면 구분 불가, 헬스장마다 모양 다름

**Phase 1.5 전략**: "AI 추측 → 원탭 확인" UX
1. 세트 시작 전 바벨 사진 한 장 촬영
2. AI가 색깔/OCR/YOLO로 분석 → "60kg 맞나요?" 표시
3. 맞으면 원탭 ✅ / 틀리면 수정
4. 80%만 맞춰도 수동 입력보다 훨씬 빠름

**경쟁력**: Tonal(월 $60 + 기기 $3,795) vs V2log(월 9,900원, 핸드폰만)

### Phase 2~3: 고급 기능

| Phase | 기능 | 방법 |
|-------|------|------|
| Phase 2 (6~12개월) | 실시간 자동 무게 감지 | YOLO 커스텀 학습 (5,000장+ 데이터) |
| Phase 2 | 폼 분석 | 관절 각도 vs 이상적 궤적 비교 |
| Phase 2 | 속도 기반 훈련(VBT) | 바벨 속도 측정 (이미 검증됨) |
| Phase 3 (12개월+) | LLM 기반 범용 카운팅 | 어떤 운동이든 자동 |
| Phase 3 | SAM 2 바벨 추적 | 프레임 간 정밀 추적 |

### 주의할 현실적 한계
- 헬스장 정확도 하락: 실험실 99% → 헬스장 88% (조명/각도/방해)
- 배터리: 카메라+AI 연속 사용 시 시간당 15~25% 소모
- 최적화: 2~3번째 프레임만 분석, 해상도 축소, 쉬는 시간 AI 중지

---

## Q2. Phase 2 무게 자동 측정의 구체적 워크플로우는?

### 전체 파이프라인 5단계

```
📸 사진 모으기 → 🏷️ 라벨 붙이기 → 🧠 AI 학습 → 📱 핸드폰에 넣기 → 🔢 무게 계산
```

### Step 1: 데이터 수집 (1~2주)

**필요량**: 최소 5,000장, 권장 10,000장+, 클래스당 300~500장

**촬영 대상 (클래스 분류)**:
- 25kg, 20kg, 15kg, 10kg, 5kg, 2.5kg, 1.25kg 플레이트
- 올림픽 바벨 (20kg 바), 빈 바벨

**촬영 다양성**: 각도(정면/45도/측면/위), 조명(밝음/어두움/자연광), 거리(1m/2m/3m), 다양한 무게 조합, 여러 헬스장

**수집 전략**:
1. 직접 촬영 (가장 좋음): 헬스장 3~5곳, 하루 500~1,000장
2. 기존 데이터셋: Roboflow Weight Plates(957장), Gym Equipment(6,620장)
3. 데이터 증강: 1장 → 5~10장 뻥튀기 (밝기/회전/반전/노이즈)

### Step 2: 라벨링 (2~3주)

사진 위에 네모 박스 그리고 "이건 25kg" 이름표 붙이는 작업

**도구**: Roboflow 추천 (웹브라우저, 무료 10,000장, YOLO 형식 내보내기)

**작업량**:
- 사진 1장: 30초~1분
- 5,000장: 약 42~83시간
- **AI 보조 라벨링**: 500장 수동 → 임시 모델 → 나머지 자동+수정 → 시간 절반

### Step 3: AI 모델 학습 (1~2주)

**모델**: YOLO11 nano 또는 YOLOv10 nano (핸드폰용, 2~2.4ms 추론)

**학습 코드 (진짜 3줄)**:
```python
from ultralytics import YOLO
model = YOLO('yolo11n.pt')
model.train(data='data.yaml', epochs=100, imgsz=640, batch=16)
```

**환경**: Google Colab 무료 GPU (5,000장 기준 2~4시간)

### Step 4: 모바일 배포

```
model.pt → model.tflite 변환 (1줄)
→ Flutter 앱 assets에 넣기
→ tflite_flutter 패키지로 실행
→ 카메라 프레임마다 AI 추론 (2~5ms)
```

### Step 5: 무게 계산 로직

AI가 감지한 플레이트 종류 × 개수를 더하기
- 바벨 바 20kg + plate_25kg × 2 + plate_10kg × 2 = 90kg
- "90kg 맞나요?" 표시 → 사용자 확인

### 전체 일정: 약 6개월, 비용 거의 0원

---

## Q3. 기존 모델을 쓸 수는 없는가? 비용이 드는가?

### 기존 모델로 되는 것 vs 안 되는 것

| 기능 | 기존 모델로 가능? | 모델 | 비용 |
|------|------------------|------|------|
| 횟수 카운팅 | ✅ 바로 가능 | MediaPipe BlazePose (학습 완료) | 0원 |
| 바벨/사람 찾기 | ✅ 어느 정도 가능 | YOLO11 (COCO 학습 완료) | 0원 |
| **플레이트 종류 구분** | ❌ **직접 학습 필요** | 커스텀 YOLO | 0원 (도구 무료) |

**왜 안 되는가**: 기존 YOLO는 COCO 데이터셋(80종 물체)으로 학습됨. 거기에 "25kg 빨간 플레이트"라는 개념이 없음. "동그란 뭔가"까지만 알고, 무게별 구분은 못 함.

### 비용 분석: 전부 0원

| 항목 | 비용 |
|------|------|
| MediaPipe | 0원 (구글 오픈소스) |
| YOLO11 | 0원 (Ultralytics 오픈소스) |
| Roboflow 라벨링 | 0원 (무료 플랜 10,000장) |
| Google Colab GPU | 0원 (무료 T4 GPU) |
| TFLite 변환 | 0원 |
| Flutter 패키지 | 0원 |
| 서버 | 0원 (핸드폰에서 전부 실행) |
| **합계** | **0원** |

유일한 투자 = 사진 찍고 라벨 붙이는 **시간**

### Transfer Learning(전이 학습) 활용

YOLO가 이미 수백만 장으로 "물체 찾는 기본 능력"을 갖고 있음 → 여기에 "플레이트 구분"만 추가 학습

- 바닥부터 학습: 50,000장 필요, 며칠 소요
- **전이 학습**: 1,000~5,000장이면 충분, 2~4시간 소요

기존 Roboflow 데이터셋(957장) + 직접 촬영 1,000장 + 증강 = 8,000~10,000장 확보 가능

---

## Q4. 헬스장 관리자가 원판 끼우면서 한 번 촬영하면 되는 거 아닌가?

### 결론: 반은 맞고, 반은 부족

**부족한 이유 — 과적합(Overfitting) 문제**:
- A 헬스장에서만 찍으면 → A에서 95% 잘 됨, B에서 40% 망함
- AI가 "플레이트 특징"이 아니라 "A 헬스장 배경+조명+바닥"까지 외워버림
- 한국 헬스장은 대부분 검은 플레이트, 제조사마다 모양 다름

**데이터 다양성 vs 정확도**:
- 1곳 200장 → 그 곳만 90%, 다른 곳 40~50%
- 3곳 1,000장 → 평균 75~80%
- 5곳 3,000장 → 평균 85~90%
- 10곳 5,000장 → 평균 90%+ (목표)

### 하지만 B2B에서는 이 아이디어가 완벽

특정 헬스장 전용 AI로 만들면:
1. 관리자가 자기 헬스장 플레이트 200~300장 촬영
2. 기본 모델에 Fine-tuning
3. 그 헬스장에서 90~95% 정확도 달성
4. 비용 0원, 1~2일이면 끝

---

## Q5. A 헬스장 관리자가 촬영→적용, B 헬스장도 마찬가지... 이러면 되는 거 아닌가?

### 결론: ✅ 맞는 방향! 추가 필요한 것 2가지

**1. 라벨링 과정 필요**
- 사진만으로는 AI가 "이 동그란 게 몇 kg인지" 모름
- 누군가가 "이건 25kg, 이건 10kg" 표시해줘야 함

**해결**: 앱 안에 "플레이트 등록" 기능 만들기
```
관리자가 하는 일:
1. 📷 바벨 사진 촬영
2. AI가 자동으로 동그란 물체 찾아서 네모 표시
3. 관리자가 각 네모 터치 → 드롭다운에서 무게 선택
4. "등록 완료!" → 서버 전송 → 자동 학습
```
→ 관리자는 **사진 찍고 터치로 무게 고르기만** 하면 됨 (2~3시간, 1회성)

**2. 범용 기본 모델 1개 (우리 팀이 만듦)**
- 관리자 데이터만으로는 처음부터 학습 어려움
- 기본 모델이 "물체 찾는 능력" 보유 → 거기에 헬스장별 추가 학습

### 최종 시스템 구조

```
[우리 팀이 한 번만 하는 것]
├── 범용 기본 모델 학습 (여러 헬스장 데이터)
├── "플레이트 등록" 앱 기능 개발
└── 자동 Fine-tuning 파이프라인 구축

[각 헬스장 관리자가 하는 것]
├── 📷 플레이트 촬영 (2~3시간, 1회성)
├── 앱에서 무게 라벨 터치로 선택
└── 끝! 나머지는 자동

[자동으로 일어나는 것]
├── 관리자 데이터 → 서버 전송
├── 기본 모델 + 이 데이터 → 자동 Fine-tuning
├── 맞춤 모델 → 해당 헬스장 사용자에게 배포
└── 그 헬스장에서 95%+ 정확도

결과:
├── B2C 일반 사용자 → 기본 모델 80~85% + 원탭 확인
└── B2B 계약 헬스장 → 맞춤 모델 90~95% + 거의 자동
```

### 사업 전략과의 연결

이 구조가 사업계획서의 **"B2C 먼저 → B2B 확장"** 전략과 정확히 일치:
- Phase 1~1.5: B2C (일반 사용자, 기본 모델 + 원탭 확인)
- Phase 2: B2B (헬스장 계약, 관리자 촬영 → 맞춤 AI)

---

## 핵심 결론 요약

1. **횟수 카운팅**: 지금 바로 가능 (MediaPipe, 0원, 88~95% 정확도)
2. **무게 자동 감지**: 5단계 파이프라인 (사진수집→라벨링→학습→배포→계산), 비용 0원
3. **기존 모델**: 횟수는 바로 가능, 플레이트 종류 구분만 직접 학습 필요
4. **헬스장별 촬영 전략**: B2B에서 완벽한 전략, 앱 내 라벨링 UI + 기본 모델 필요
5. **전체 비용**: 소프트웨어/AI 도구 전부 무료, 유일한 투자는 시간과 노력

---

## 참고 문서
- 기술 조사 보고서: `docs/reference/CV_무게측정_횟수카운팅_최신기술_보고서_2026.md`
- CV 피벗 사업계획서: `docs/reference/CV_피벗_사업계획서_Fica_2026.md`
